\section{Stochastic adjustment of the network weights}\label{stochastic}

\subsection*{Problem position}

Let us consider the problem of optimizing the probabilistic distribution $\tilde{p}(\tilde{\bf x} = {\bf x})$ of a network output, as a function of the desired distribution $\bar{p}(\bar{\bf o} = {\bf o})$ of a root network. Since we are in a multi-dimensional and dynamic framework, with continuous values, it is  intractable to consider as it the distribution, but only a parametric model of it, and adjust the parameters of this model. The key point is that we are going to consider observables of the output, written 
\eqline{{\Omega}_{k}  \deq {\mathbb E}[\omega_{k}] \simeq \frac{1}{T - \tau_k} \, \sum_{t = 0}^{T - \tau} \omega_{k}(t),}
for an observable  $\omega_{k}(x_n(t) \cdots x_n(t-\tau_k))$ of a given rank $\tau_k$, using the ergodic assumption to approximate numerically its value.

Let us, for instance, consider that the network output mean $\tilde{\Omega}_{n,\bullet}$ and auto-correlation in a $\tau = \{0, \Delta\}$ time window $\tilde{\Omega}_{n,\tau}$, corresponds to the desired statistical paremeters:
\eqline{\begin{array}{rclrcl}
   {\Omega}_{n} &=& {\mathbb E}[\omega_{n}(t)], & \omega_{n}(t) &\deq& {o}_n(t) \\
   {\Omega}_{n,\tau}  &=& {\mathbb E}[\omega_{n,\tau}(t)] & \omega_{n,\tau}(t) &\deq& {o}_n(t) \, {o}_n(t - \tau), \\
\end{array}}
the normalized temporal auto-correlation being: 
\eqline{C_{n,\tau} = ({\Omega}_{n,\tau} - {\Omega}_{n}^2) / ({\Omega}_{n,0} - {\Omega}_{n}^2).}
We thus do not constraint the output desired values directly but only some momentum expectation.
We could also have considered higher order momenta, e.g., kewness and kurtosis, or spatial correlations, and so on.

A step further we must introduce the notion of {\em normalized observable} $\Upsilon_k$, given a desired values $\bar{\Omega}_{k}$, thats maps the observable value ${\Omega}_{k}$ onto a dimension-less normalized monotonic error function. For the mean ${\Omega}_{n}$ we propose
\eqline{\Upsilon_n = \tanh\left(({\Omega}_{n} - \bar{\Omega}_{n}) \left/ \mathring{\Omega}_{n} \right.\right), 
  \mathring{\Omega}_{n} = \left\{ \begin{array}{rll} 
 \bar{\Omega}_{n} & \mbox{if} & |\bar{\Omega}_{n}| > \epsilon \\ 
 \sqrt{\bar{\Omega}_{n,0}} & \mbox{if} & |\bar{\Omega}_{n}| < \epsilon, \bar{\Omega}_{n,0} > \epsilon^2 \\ 
  1 & \mbox{otherwise,} \end{array} \right.}
in words the mean difference is normalized using the expected mean, if not negligible, or the standard deviation if given, though a normalized sigmoid profile. For second order momenta we can consider,.e.g., the normalized correlation, writing:
\eqline{\Upsilon_{n,\tau} = \tanh\left(({\Omega}_{n,\tau} - \bar{\Omega}_{n,\tau}) \left/ (\bar{\Omega}_{n,0} - \bar{\Omega}_{n}^2) \right.\right),}
providing the denominator does not vanish, normalizing the estimated observable ${\Omega}_{n,\tau}$ against desired observable values $\bar{\Omega}_k$. Our assumption is that there is always an application dependent pertinent way of defining such a normalization mapping. More generaly we require $\Upsilon_k$ to be a point-wise separating function
\eqline{\Upsilon_k = \rho_{\bar{\Omega}}\left({\Omega}_{k} - \bar{\Omega}_{k}\right), \mbox{ with } \rho_{\bar{\Omega}}(u) = 0 \Leftrightarrow u = 0 \mbox{ and } \rho_{\bar{\Omega}}(u) \in [-1, 1].}

\subsubsection*{Considering a general model}

Adapting the development given in \cite{vasquez:inria-00574954} for binary distribution, we propose to minimize the KL-divergence, considering maximal entropy Gibbs distributions. We are going to propose to adjust the network weights in order to minimize an approximation of the KL-divergence between the desired and simulated distribution.

If we look for a distribution of probability with maximal entropy and which observable $\omega_{k}$ correspond to some expectation values ${\Omega}_{k}$, we obtain:
\eqline{p({\bf x}) = \frac{\exp\left(\sum_k \lambda_k \, {\omega}_{k}({\bf x}) \right)}{Z_p({\bf \lambda})},}
where the denominator guaranties $\int_{{\bf x}} p({\bf x}) = 1$ and is called the partition function\footnote{{\bf Maximal entropy distribution.} Given expectation  ${\Omega}_{k}$  of observable $\omega_{k}(t)$ we state that we look for a probability distribution of maximal entropy which corresponds to the observable expectation. This writes, with Lagrangian multipliers $\lambda_k$:
\eqline{\min_{\bf \lambda} 
\underbrace{\int_{\bf x} p({\bf x}) \log(p({\bf x}))}_{entropy} +
\underbrace{\lambda_{0} \left(\int_{\bf x} p({\bf x}) -1 \right)}_{normalization} -
\underbrace{\sum_k \lambda_{k} \left(\int_{\bf x} p({\bf x}) \, \omega_{k}({\bf x}) - {\Omega}_{k}\right)}_{observations}}
and the functional derivative of this criterion yields:
\eqline{p({\bf x}) = \exp\left(\sum_k \lambda_k \, {\omega}_{k}({\bf x})\right) / Z_p({\bf \lambda}),}
as easily obtained from the normal equation derivation, see e.g.:
\\ \centerline{\href{https://en.wikipedia.org/wiki/Maximum\_entropy\_probability\_distribution\#Proof}{https://en.wikipedia.org/wiki/Maximum\_entropy\_probability\_distribution\#Proof}.}\hr}, topological pressure or free energy. The quantity $Z_p({\bf \lambda})$ has no closed form beyond simple cases, and can be numerically estimated as:
\eqline{Z_p({\bf \lambda}) = \int_{\bf x} \exp\left(\sum_k \lambda_k \, {\omega}_{k}({\bf x})\right) \simeq \frac{1}{T - \tau} \, \sum_{t = 0}^{T- \tau} \exp\left(\sum_k \lambda_k \, {\omega}_{k}(t)\right)}, under the ergodic assumption, $\tau$ being chosen for all observable ${\omega}_{k}(t)$ to be defined.

\subsubsection*{Fitting a Gibbs distribution}

A step further, it appears that minimizing the KL-divergence between the observed distribution $\bar{p}(\bar{\bf o})$ and the Gibbs model corresponds to adjust the parameters $\bar{\bf \lambda}$ in order the predicted observable expectation $\Omega_k({\bf \lambda})$ to get as closed as possible to the desired observable expectation $\bar{\Omega}_{k}$, which is a standard estimation problem (in a nutshell, the trick is to minimize the criterion gradient, not the criterion itself\footnote{{\bf Fitting the Gibbs parameters distribution}. For the sake of completeness, let us detail how such estimation can be performed. If we consider the KL-divergence between the observed distribution $\bar{p}(\bar{\bf o})$ and the model approximate distribution $q({\bf x}))$, we easily derive: 
\eqline{\begin{array}{rcl}
d_{KL}(\bar{p}(\bar{\bf o})\|q({\bf x})) 
&=& \int \bar{p}(\bar{\bf o}) \, \log\left(\frac{\bar{p}(\bar{\bf o})}{q({\bf x})}\right) \\
&=& \int \bar{p}(\bar{\bf o}) \, \log\left(\bar{p}(\bar{\bf o})\right) - \int \bar{p}(\bar{\bf o}) \, \log\left(q({\bf x})\right) \\
&=& -h_{\bar{\bf o}} - \int \bar{p}(\bar{\bf o}) \log\left(q({\bf x})\right) \\
&=& -h_{\bar{\bf o}} - \int \bar{p}(\bar{\bf o}) \left(\sum_k \lambda_k \, \omega_{k} - \log(Z({\bf \lambda})) \right) \\
&=& -h_{\bar{\bf o}} - \sum_k \lambda_k \, \bar{\Omega}_{k} + 1 \, \log(Z_q({\bf \lambda})) \\
\end{array}}
combining the previous equations, and since the term $h_{\bar{\bf o}} \deq -\int \bar{p}(\bar{\bf o}) \log(\bar{p}(\bar{\bf o}))$ is the observed entropy and is constant with respect to the parameter to estimate, we are left with the following criterion, which in fact corresponds to cross-entropy maximization $\min_{\bf \lambda} {\cal J}$, with: 
\eqline{\begin{array}{rcl}
 {\cal J} &=& \log\left(Z_q({\bf \lambda})\right) - \sum_k \lambda_k \, \bar{\Omega}_{k} \\
 \partial_{\lambda_k} {\cal J} &=& \Omega_k({\bf \lambda}) - \bar{\Omega}_{k} \\
 \partial_{\lambda_k\, \lambda_l} {\cal J} &=& \Omega_{kl}({\bf \lambda}) \\
\end{array}}
writing $\omega_{kl}(t) = \omega_k(t) \, \omega_l(t)$, and $\Omega_{kl} = {\mathbb E}[\omega_{kl}]$. This computation comes from the fact that:
\eqline{\begin{array}{rcl}
Z_q({\bf \lambda}) 
&=& \int_{{\bf x}} \exp\left(\sum_k \lambda_k \, {\omega}_{k}({\bf x}) \right) \\
\partial_{\lambda_k} Z_q({\bf \lambda}) 
&=& \int_{{\bf x}} \exp\left(\sum_k \lambda_k \, {\omega}_{k}({\bf x}) \right) \, {\omega}_{k}({\bf x}) \\
&=& \int_{{\bf x}} Z_q({\bf \lambda}) \, q({\bf x}) \, {\omega}_{k}({\bf x}) \\
&=& Z_q({\bf \lambda}) \, {\Omega}_{k}({\bf \lambda}),
\end{array}}
and it is easy to approximate:
\eqline{\begin{array}{lrcl}  
\Omega_{l}({\bf \lambda}) 
&\deq& \int_{\bf x} \frac{\exp\left(\sum_k \lambda_k \, \omega_{k}\right)}{Z_q({\bf \lambda})} \omega_l(t)\\
&\simeq& \frac{1}{T - \tau_l} \, \sum_t \omega_l(t) \\
\end{array}}
under the ergodic assumption.

As a consequence, despite the caveat that $Z_q({\bf \lambda})$ calculation is usually not tractable, this allows us to implement some paradigm that tends to minimize the criterion gradient (since at a criterion minimum, the gradient vanishes):
\eqline{\bar{\lambda} = \mbox{arg min}_\lambda \rho\left(\Omega({\bf \lambda}) - \bar{\Omega}\right),} for some suitable point separating positive function $\rho()$. 

This design choice is valid because the topological pressure is convex with respect to ${\bf \lambda}$, so that the criterion is convex \cite{vasquez:inria-00574954}. As a consequence, the criterion is minimal when the gradient magnitude vanishes, i.e. is minimal too, while the criterion decreases with the gradient magnitude, thanks to being a convex criterion.\hr}). As a consequence, given a desired output $\bar{\bf o}$ and a choice of observable $\omega_k$ we can estimate the maximal entropy parameters $\bar{\bf \lambda}$.

\subsubsection*{Statistical weight adjustment from the parametric model}

Given of set of desired observable values $\bar{\Omega}_k$, with the corresponding Gibbs model $\hat{p}(\bar{\bf o})$ parameterized by $\bar{\bf \lambda}$ and adjusted on the reference samples $\bar{\bf o}$, we now can state the problem of adjusting the network weights. We consider the KL-divergence between the observed distribution $\bar{p}(\bar{\bf o})$, approximated by the related Gibbs model, and the network simulation $\tilde{p}_{\bf W}(\tilde{\bf x})$, parameterized by the network weights ${\bf W}$. The network is viewed here as a parametric model of the observed distribution. 

Since the network simulation is brought to the desired reference samples distribution, modeled as a Gibbs distribution, we are going to assume that the network simulation can itself be represented by a Gibbs distribution with the goal to adjust the weights in order the related divergence $d_{KL}(\bar{p}(\bar{\bf o})\|\tilde{p}(\tilde{\bf x}))$. As before, we can replace the KL-divergence minimization by the minimization of the gradient, i.e., some point separating positive function of the difference between the measured observable ${\Omega}_{k}$ on the simulation and the desired value $\bar{\Omega}_{k}$.

This is the point where we use the normalized observable and propose to minimize:
\begin{equation} \label{kl-criterion} \rho({\bf x}) \deq \sum_k |\Upsilon_k|^d = \sum_k |\rho_k\left(\bar{\Omega}_{k} - {\Omega}_{k}({\bf W})\right)|^d.\end{equation}
and have numerically experimented that $d=1$ seems more efficient than $d=2$.

\subsubsection*{Boostrapping the network estimation}

Given the previous criterion, we consider a network simulation $x_n(t)$, with the goal to modify the related network weights in order the network output observable ${\Omega}_k$ to be as closed as possible to the desired observable $\bar{\Omega}_k$. To this end, we define desired values $\hat{x}_n(t)$, as follows
\eqline{\min_{\hat{x}_n(t)} \frac{1}{2} \, \sum_{nt} (\hat{x}_n(t) - x_n(t))^2 + \sum_k \lambda_k \left[\bar{\Omega}_{k} - \Omega_k({\bf x}) \right]}
in words: The desired values are the closest values with respect to the present simulation that match the desired observable, which is a standard non-linear constrained least-square 2nd order recurrent scheme (see e.g., \cite{vieville:inria-00074888}). Such desired values may be used to provide local solutions to the estimation problem.


