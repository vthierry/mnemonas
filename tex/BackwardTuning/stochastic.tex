\section{Stochastic adjustment of the network weights}\label{stochastic}

Let us consider the problem of optimizing the probabilistic distribution $\tilde{p}(\tilde{\bf x} = {\bf x})$ of a network output, as a function of the desired distribution $\bar{p}(\bar{\bf o} = {\bf o})$ of a root network. Since we are in a multi-dimensional and dynamic framework, with continuous values, it is  intractable  to consider as it the distribution, but only a parametric model of it, and adjust the parameters of this model. 

\subsubsection*{An illustrative example}

Let us, for instance, consider that it is important that the network output mean $\tilde{\Omega}_{n,\bullet}$ and auto-correlation in a $\tau = \{0, \Delta\}$ time window $\tilde{\Omega}_{n,\tau}$, correspond to some desired values:
\eqline{\begin{array}{rclrcl}
   \bar{\Omega}_{n,\bullet}  &\deq& \frac{1}{T} \, \sum_{t = 0}^{T - 1} \omega_{n,\bullet}(t), & \omega_{n,\bullet}(t) &\deq& \bar{o}_n(t) \\
   \bar{\Omega}_{n,\tau}  &\deq& \frac{1}{T - \tau} \, \sum_{t = 0}^{T - \tau - 1} \omega_{n,\tau}(t) & \omega_{n,\tau}(t) &\deq& \bar{o}_n(t) \, \bar{o}_n(t - \tau), \\
\end{array}}
the normalized temporal auto-correlation being: 
\eqline{C_{n,\tau} = (\bar{\Omega}_{n,\tau} - \bar{\Omega}_{n,\bullet}^2) / (\bar{\Omega}_{0,\tau} - \bar{\Omega}_{n,\bullet}^2).}
We thus do not constraint the output desired values directly but only some momenta expectation.

Beyond this example, we thus consider observable $\omega_{k}(x_n(t) \cdots x_n(t-\tau_k))$ of a given rank $\tau_k$ and their expectation on the desired distribution $\Omega_{k}$. We could also have considered higher order momenta, e.g., consider mean, standard-deviation, skewness and kurtosis, or spatial correlations, and so on.

\subsubsection*{Considering a general model}

Adapting the development given in \cite{vasquez:inria-00574954} for binary distribution, we propose to minimize the KL-divergence, considering maximal entropy Gibbs distributions. We are going to propose to adjust the network weights in order to minimize an approximation of the KL-divergence between the desired and simulated distribution.

If we look for a distribution of probability with maximal entropy and which observable $\omega_{k}$ correspond to some expectation values ${\Omega}_{k}$, we obtain:
\eqline{p({\bf x}) = \frac{\exp\left(\sum_k \lambda_k \, {\omega}_{k}({\bf x}) \right)}{Z_p({\bf \lambda})},}
where the denominator guaranties $\int_{{\bf x}} p({\bf x}) = 1$ and is called the partition function\footnote{{\bf Maximal entropy distribution.} Given expectation  ${\Omega}_{k}$  of observable $\omega_{k}(t)$ we state that we look for a probability distribution of maximal entropy which corresponds to the observable expectation. This writes, with Lagrangian multipliers $\lambda_k$:
\eqline{\min_{\bf \lambda} 
\underbrace{\int_{\bf x} p({\bf x}) \log(p({\bf x}))}_{entropy} +
\underbrace{\lambda_{0} \left(\int_{\bf x} p({\bf x}) -1 \right)}_{normalization} -
\underbrace{\sum_k \lambda_{k} \left(\int_{\bf x} p({\bf x}) \, \omega_{k} - {\Omega}_{k}\right)}_{observations}}
and the functional derivative of this criterion yields:
\eqline{p({\bf x}) = \exp\left(\sum_k \lambda_k \, {\omega}_{k}({\bf x})\right) / Z_p({\bf \lambda}),}
as easily obtained from the normal equation derivation, see e.g.:
\\ \centerline{\href{https://en.wikipedia.org/wiki/Maximum\_entropy\_probability\_distribution\#Proof}{https://en.wikipedia.org/wiki/Maximum\_entropy\_probability\_distribution\#Proof}.}\hr}, topological pressure or free energy. The quantity $Z_p({\bf \lambda})$ has no closed form beyond simple cases, and can be numerically estimated as:
\eqline{Z_p({\bf \lambda}) = \int_{\bf x} \exp\left(\sum_k \lambda_k \, {\omega}_{k}({\bf x})\right) \simeq \frac{1}{T - \tau} \, \sum_{t = 0}^{T- \tau} \exp\left(\sum_k \lambda_k \, {\omega}_{k}(t)\right)}, under the ergodic assumption, $\tau$ being chosen for all observable ${\omega}_{k}(t)$ to be defined.

\subsubsection*{Fitting a Gibbs distribution}

A step further, it appears that minimizing the KL-divergence between the observed distribution $\bar{p}(\bar{\bf o})$ and the Gibbs model corresponds to adjust the parameters $\bar{\bf \lambda}$ in order the predicted observable expectation $\Omega_k({\bf \lambda})$ to get as closed as possible to the desired observable expectation $\bar{\Omega}_{k}$, which is a standard estimation problem (in a nutshell, the trick is to minimize the criterion gradient, not the criterion itself\footnote{{\bf Fitting the Gibbs parameters distribution}. For the sake of completeness, let us detail how such estimation can be performed. If we consider the KL-divergence between the observed distribution $\bar{p}(\bar{\bf o})$ and the model approximate distribution $q({\bf x}))$, we easily derive: 
\eqline{\begin{array}{rcl}
d_{KL}(\bar{p}(\bar{\bf o})\|q({\bf x})) 
&=& \int \bar{p}(\bar{\bf o}) \, \log\left(\frac{\bar{p}(\bar{\bf o})}{q({\bf x})}\right) \\
&=& \int \bar{p}(\bar{\bf o}) \, \log\left(\bar{p}(\bar{\bf o})\right) - \int \bar{p}(\bar{\bf o}) \, \log\left(q({\bf x})\right) \\
&=& -h_{\bar{\bf o}} - \int \bar{p}(\bar{\bf o}) \log\left(q({\bf x})\right) \\
&=& -h_{\bar{\bf o}} - \int \bar{p}(\bar{\bf o}) \left(\sum_k \lambda_k \, \omega_{k} - \log(Z({\bf \lambda})) \right) \\
&=& -h_{\bar{\bf o}} - \sum_k \lambda_k \, \bar{\Omega}_{k} + 1 \, \log(Z_q({\bf \lambda})) \\
\end{array}}
combining the previous equations, and since the term $h_{\bar{\bf o}} \deq -\int \bar{p}(\bar{\bf o}) \log(\bar{p}(\bar{\bf o}))$ is the observed entropy and is constant with respect to the parameter to estimate, we are left with the following criterion, which in fact corresponds to cross-entropy maximization $\min_{\bf \lambda} {\cal J}$, with: 
\eqline{\begin{array}{rcl}
 {\cal J} &=& \log\left(Z_q({\bf \lambda})\right) - \sum_k \lambda_k \, \bar{\Omega}_{k} \\
 \partial_{\lambda_k} {\cal J} &=& \Omega_k({\bf \lambda}) - \bar{\Omega}_{k} \\
 \partial_{\lambda_k\, \lambda_l} {\cal J} &=& \Omega_{kl}({\bf \lambda}) \\
\end{array}}
writing $\omega_{kl}(t) = \omega_k(t) \, \omega_l(t)$, and $\Omega_{kl} = {\mathbb E}[\omega_{kl}]$. This computation comes from the fact that:
\eqline{\begin{array}{rcl}
Z_q({\bf \lambda}) 
&=& \int_{{\bf x}} \exp\left(\sum_k \lambda_k \, {\omega}_{k}({\bf x}) \right) \\
\partial_{\lambda_k} Z_q({\bf \lambda}) 
&=& \int_{{\bf x}} \exp\left(\sum_k \lambda_k \, {\omega}_{k}({\bf x}) \right) \, {\omega}_{k}({\bf x}) \\
&=& \int_{{\bf x}} Z_q({\bf \lambda}) \, q({\bf x}) \, {\omega}_{k}({\bf x}) \\
&=& Z_q({\bf \lambda}) \, {\Omega}_{k}({\bf \lambda}),
\end{array}}
and it is easy to approximate:
\eqline{\begin{array}{lrcl}  
\Omega_{l}({\bf \lambda}) 
&\deq& \int_{\bf x} \frac{\exp\left(\sum_k \lambda_k \, \omega_{k}\right)}{Z_q({\bf \lambda})} \omega_l(t)\\
&\simeq& \frac{1}{T - \tau_l} \, \sum_t \omega_l(t) \\
\end{array}}
under the ergodic assumption.

As a consequence, despite the caveat that $Z_q({\bf \lambda})$ calculation is usually not tractable, this allows us to implement some paradigm that tends to minimize the criterion gradient (since at a criterion minimum, the gradient vanishes):
\eqline{\bar{\lambda} = \mbox{arg min}_\lambda |\Omega_{l}({\bf \lambda}) - \bar{\Omega}_{k} |.}
One example of algorithm writes:
\\ \hphantom{2mm} {\em Input} : The desired observable values $\bar{\Omega}_{k}$ and the distribution samples $\bar{\bf o}$.
\\ \hphantom{2mm} {\em Output} : The estimated $\bar{\lambda}_k$.
\\ \hphantom{4mm} - Starts with ${\bf \lambda}_0 = 0$ and a regularization parameter $\upsilon = 1$.
\\ \hphantom{4mm} - At a given iteration $i$
\\ \hphantom{4mm} -- Computes $\Omega_k({\bf \lambda})$ and $\Omega_{kl}({\bf \lambda})$ for a given value of ${\bf \lambda}$ from a random draw $\pi(t)$.
\\ \hphantom{4mm} -- In order to obtain ${\bf \lambda}_{i} = d{\bf \lambda} + {\bf \lambda}_{i-1}$ solve the regularized linear problem: 
\eqline{d{\bf \lambda} = \mbox{arg min}_{d{\bf \lambda}} |d{\bf \lambda}|, \;\;\; \upsilon \, \partial {\cal J} + (1 - \upsilon) \, \partial^2 {\cal J} \, {\bf \lambda}_{i-1} = \partial^2 {\cal J} \, d{\bf \lambda}}
calculating the SVD of $\partial^2 {\cal J}$ in order to consider its pseudo-inverse.
\\ \hphantom{4mm} -- If $\|\partial {\cal J}\|$ does not decreases reduce $\upsilon$ and repeat until $\upsilon$ vanishes.
\hr}). As a consequence, given a desired output $\bar{\bf o}$ and a choice of observable $\omega_k$ we can estimate the maximal entropy parameters $\bar{\bf \lambda}$.

\subsubsection*{Statistical weight adjustment from the parametric model}

Given set of desired observable values $\bar{\Omega}_k$, with the corresponding Gibbs model $\hat{p}(\bar{\bf o})$ parameterized by $\bar{\bf \lambda}$ and adjusted on the reference samples $\bar{\bf o}$, we now can state the problem of adjusting the network weights. We consider the KL-divergence between the observed distribution $\bar{p}(\bar{\bf o})$, approximated by the related Gibbs model, and the network simulation $\tilde{p}_{\bf W}(\tilde{\bf x})$, parameterized by the network weights ${\bf W}$. The network is viewed here as a parametric model of the observed distribution. 

Since the network simulation is brought to the desired reference samples distribution, modeled as a Gibbs distribution, we are going to assume that the network simulation can itself be represented by a Gibbs distribution:
\eqline{\tilde{p}(\tilde{\bf x}) \simeq \exp\left(\sum_k \tilde{\lambda}_k \, {\omega}_{k}({\bf x})\right) / Z_{\tilde{p}}(\tilde{\bf \lambda}),}
yielding, using similar algebra as before:
\eqline{\begin{array}{rcl} d_{KL}(\bar{p}(\bar{\bf o})\|\tilde{p}(\tilde{\bf x})) 
 &=& \int p(\bar{\bf o}) \log\left(\frac{\bar{p}(\bar{\bf o})}{\tilde{p}(\tilde{\bf x})}\right) \\
 &\simeq& \int p(\bar{\bf o}) \log\left(\frac{\hat{p}(\bar{\bf o})}{\tilde{p}(\tilde{\bf x})}\right) \\ &=& \sum_k (\bar{\lambda}_k - \tilde{\lambda}_k) \, \bar{\Omega}_{k}
          + \log(Z_{\tilde{p}}(\tilde{\bf \lambda})/Z_{\bar{p}}(\bar{\bf \lambda})) \\
\end{array}}
with the goal to adjust the weights in order the related $\tilde{\bf \lambda}$ to minimize this divergence. As before, we can replace the KL-divergence minimization by the minimization of the gradient magnitude. This design choice is valid because the topological pressure is convex with respect to ${\bf \lambda}$, so that the criterion is convex \cite{vasquez:inria-00574954}. As a consequence, the criterion is minimal when the gradient magnitude vanishes, i.e. is minimal too, while the criterion decreases with the gradient magnitude, thanks to being a convex criterion.

The gradient writes $\partial_{\tilde{\lambda}_k} d_{KL}(\bar{p}(\bar{\bf o})\|\tilde{p}(\tilde{\bf x})) = \tilde{\Omega}_{k}(\tilde{\bf \lambda}_{\bf W}) - \bar{\Omega}_{k}$, and we propose to consider the following weighted ${\cal L}^1$ norm:
\begin{equation} \label{kl-criterion} \rho({\bf x}) \deq \sum_k |\bar{\lambda}_k| \, \left|\bar{\Omega}_{k} - \frac{1}{T-\tau_k} \sum_t \omega_k(t)\right|. \end{equation}
The reason of this second design choice is that it has the same order of magnitude as the $d_{KL}(\bar{p}(\bar{\bf o})\|\tilde{p}(\tilde{\bf x}))$ with respect to the observable, i.e.:
\eqline{|\partial_{\bar{\Omega}_k} d_{KL}(\bar{p}(\bar{\bf o})\|\tilde{p}(\tilde{\bf x}))| = |\partial_{\bar{\Omega}_k} \rho({\bf x})| = |\bar{\lambda}_k|,}
so that we expect the numerical condition of the original criterion and the related gradient magnitude to be similar. At the experimental level we have observed that such ${\cal L}^1$ criterion seems more efficient than the corresponding ${\cal L}^2$ criterion.

\subsubsection*{Boostrapping the network estimation}

Given the previous criterion, we consider a network simulation $x_n(t)$, with the goal to modify the related network weights in order the network output observable to be $\frac{1}{T-\tau_k} \sum_t \omega_k(t)$ to be as closed as possible to the desired observable $\bar{\Omega}_k$. To this end, we define desired values $\hat{x}_n(t)$, as follows
\eqline{\min_{\hat{x}_n(t)} \frac{1}{2} \, \sum_{nt} \|\hat{x}_n(t) - x_n(t)\|^2 + \sum_k \lambda_k \left[\bar{\Omega}_{k} - \frac{1}{T-\tau_k} \sum_t \left. \omega_k(t)\right|_{\hat{x}} \right]}
in words: The desired values are the closest values with respect to the present simulation that match the desired observable, while the normal equations yield the recurrent equation:
\eqline{\begin{array}{rcl}
  \hat{x}_n(t) &\leftarrow& x_n(t) + \sum_k \frac{1}{T-\tau_k} \, \lambda_k \, \sum_t \partial_{x_n(t)} \omega_k(t) \\
  \lambda_k &\simeq& \left[ \frac{1}{T-\tau_k} \, \frac{1}{T-\tau_{k'}} \, \sum_{nt} \partial_{x_n(t)} \omega_{k'}(t) \, \partial_{x_n(t)} \omega_{k}(t)^T \right]^{\dagger} \, \left[\bar{\Omega}_{k'} - \frac{1}{T-\tau_k'} \sum_t \omega_{k'}(t)\right] \\
\end{array}}
which is a standard non-linear constrained least-square 2nd order recurrent scheme (see e.g., \cite{vieville:inria-00074888}). In other words, we iteratively compute the projection $\hat{x}_n(t)$ of the present simulation $x_n(t)$ onto the manifold defined by $\bar{\Omega}_{k} = \frac{1}{T-\tau_k} \sum_t \omega_k(t)$, i.e., such that the desired values observables equal the desired observable values. Here, $\partial_{\bf x} \omega_{k}(t)$ corresponds to the local norma of the manifold, and since observables are mainly monomials of degree less than $D$, we can write for some $u_{nt} \in \{0, 1\}, d_{nt} \in \{0, D\}$ defining the monomial:
\eqline{\omega_{k}(t) = \prod_{nt} u_{nt} \, x_{n}(t)^{d_{nt}}, \mbox{ yielding } \partial_{x_{n't'}} \omega_k(t) = d_{n't'} \, \frac{\omega_{k}(t)}{x_{n't'}}}
which is well-defined, including for $x_{n't'} = 0$.

Such desired values may be used to provide local solutions to the estimation problem.


