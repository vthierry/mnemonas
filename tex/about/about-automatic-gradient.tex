\documentclass{article}\usepackage{hyperref}\usepackage{graphicx}\usepackage{amsmath}\usepackage{amsfonts}\newcommand{\deq}{\stackrel {\rm def}{=}} \newcommand{\eqline}[1]{\\\centerline{$#1$}\\}\newcommand{\tab}{\hphantom{6mm}}\newcommand{\well}[1]{\vspace{0.3cm}\hspace{-2cm}{\tt #1}} \begin{document}

\section*{Introduction}

\subsection*{Problem position}

Automated machine learning\footnote{The notions of ``\href{https://en.wikipedia.org/wiki/Automated\_machine\_learning}{automated-machine-learning}'', ``\href{https://en.wikipedia.org/wiki/Meta_learning_(computer_science)}{meta-learning}'', including ``\href{https://en.wikipedia.org/wiki/Meta-optimization}{meta-optimization}'' and ``\href{https://en.wikipedia.org/wiki/Hyperparameter_(machine_learning)}{hyperparameter}'' and the related ``\href{http://neupy.com/2016/12/17/hyperparameter\_optimization\_for\_neural\_networks.html}{hyperparameter optimization}'', have precise meaning in machine-learning, and we assume this is known to the reader.} is ``the process of automating the end-to-end process of machine learning'', because the complexity of adjusting the hyperparameters, including selecting a suitable method, becomes easily time-consuming when not intractable. To this end, the general idea is to consider a standard machine-learning algorithm and to add on ``top of it'' another algorithmic mechanism, e.g., another machine learning algorithm dedicated to automatic hyperparameter adjustment, with the caveat of generating other hyperparameters for the meta-learning algorithm and without formal guaranty that this accumulation of mechanisms is optimal.

The key setting is to adjust the model parameter by optimizing the criterion on a {\em learning} data set, and validate the hyperparameter choice by rerunning the optimization for different hyperparameter values on a different {\em validation} data set, while the final performance is evaluated on another {\em test} set. 

\subsection*{Related work}

As being an everyday concrete problem for the machine learning community, there is a huge literature on hyperparameter adjustment of optimization algorithms. A recent review of automatic selection methods for machine learning algorithms and hyperparameter values is available \cite{luo2016review}, while the state of the art regarding hyper-heuristics has been made by \cite{burke2013hyper}, an introducing overview about automatic hyperparameter optimization and model selection for supervised machine learning is available in this student work \cite{bermudez2014automatic}. Hyperparameter adjustment packages are available with every machine learning framework, searching through the joint space of hyperparameter settings such as, e.g., Hyperopt \cite{bergstra2013hyperopt} or, e.g., Auto-WEKA \cite{kotthoff2017auto}. Further reviewing these methods is beyond the scope of this paper.

As far as gradient adjustment is concerned one track is to consider algorithms for which hyper-parameter tuning requires little tuning (e.g., considering the ADAM approach of \cite{kingma2014adam}, where the first-order gradient-based optimization of stochastic objective functions is based on adaptive estimates of lower-order momenta, or improving vanilla or natural gradient methods by automatic adjustment of the local optimization \cite{marceau2016practical}). A step further, gradient has also been adjusted adjustment has been considered using a sub-set of the network parameters, considering that the intrinsic dimension of the objective landscape is below the global number of parameters \cite{li2018measuring}.

\subsection*{Proposed contribution}


\section*{Problem setting}

\subsection*{Notations}

To develop our idea we are going to consider a simple input-output transformation :
\eqline{{\bf o} = {\bf f}_{\bf w}({\bf i}),}
mapping an input ${\bf i} \in {\cal R}^I$ onto an output ${\bf o} \in {\cal M} \subset {\cal R}^O$, as a function of parameters (e.g., network weights or architecture size) ${\bf w} \in {\cal R}^W$, and a sequence of input ${\bf i}_n, t \in \{1, N\}$, coupled with a output loss function sequence $l_n(\cdot)$ with the goal to minimize the loss expectation: 
\eqline{{\bf w}^\bullet = \mbox{arg max}_{\bf w} \mathbb{E}[l({\bf f}_{\bf w}({\bf i}))]}
and would like, given a learning set, to minimize this expectation on subsequent input.

The computed values lives in a compact (thus bounded) subset ${\cal M} \subset {\cal R}^O$. The extrinsic dimension $O$ is expected to be large. Qualitative values simply corresponds to discrete components of ${\cal M}$.


\bibliographystyle{alpha}\bibliography{../bib/vthierry} \end{document}
