\documentclass{article}

\begin{document}

\section*{Introduction}

In the 90's the best computer vision algorithms have been well-formalized in a variational framework or using partial differential equations, with the consequence to obtain robust, performant and well-understood algorithms \cite{aubert-kornprobst:06}. Graphcut based algorithms have been designed in the continuation of these research tracks (e.g., \cite{boykov-kolmogorov:04} introducing also machine-learning methods (e.g. \cite{vieville-crahay:04,zhu-xu-etal:06,etyngier-segonne-etal:07b}). Then deep-learning methods have proven to experimentally over-performed computer-vision mechanisms thanks to learning capability on big data sets (e.g., \cite{Farabet2013Learning}). Deep-learning layers integrate some of these computer-vision algorithms, but they mainly rely on rather stereotypical mechanisms such as convolution networks (in a nutshell a simple linear filter followed by a static non-linearity [c est toujours vrai Ã§a ?]) \cite{Bengio2009Learning}. Why not make the best out of both approaches ?

In this preliminary work we explore two tracks :

On one hand, we simply trivially add computer vision algorithms, such as total-variation image enhancement in order to experimentally show whether the block-combination of both paradigm could be of some benefit.
\
On the other hand, we propose a new non-linear convolution network structure, where the underlying diffusion operator induced by the convolution is no more a fixed parameter diffusion operator (fixed parameter values being obtained by supervised learning on a big data set), but where the weights values are parameterized functions (derived from, e.g., anysotropic non-linear diffusion operators), these parameters being learned from usual deep-learning paradigms.
[c est dommange qu on ait pas trois mains]

Regarding the second approach, the intertwine of both computer-vision and deep-learning has several advantages, at least in our illustrative example :
\\  - the convolution mask is defined by less parameters, because we introduce a-priori constrained to remain on a suitable architecture;
\\  - the convolution mask parameters is not only adapted to the general data-set statistics, via supervised learning, but also adapts to the each incoming data, applying computer vision formalism;
\\  - we also show that at the algorithmic level, that implementing such architecture is no more than considering additional layers, with or without feedback, and experiment it with the TensorFlow approach;
\\  - we have a safe and well-formalized way to introduce feedback in the usual deep-learning architecture, since we can relate such mechanism to a convergent variational scheme (or EDP scheme).
 
Another more putative consequence is the fact we may obtain more bio-plausible architectures. This is an hypothesis. One argument is that the brain architecture of the visual system, for instance, is not a deep feed-forward architecture at all contrary to a widespread statement, because feedback via the thalamic hub (namely the pulvinar) play a major role. It is more a system with short-cuts, iterative connections, and we must have a well-defined framework to properly specified such an not feedforward architecture. The computer vision variational framework may be one solution. Another argument is related to the generic need to not only extract characteristics in an image to perform (object (localization|detection)|scene (parsing|classification)) but to segment the image. This is usually performed in deep-learning architecture by either adding ad-hoc mechanisms (e.g. super-pixel grouping/voting mechanism) or it is simply left to the blind weight crowd adjustment. In the visual system, the different visual map segmentation seems to be performed at several stage (including in the retina coding, where spike synchronization likely corresponds to units of the same region), but within the hierarchical construction of the visual cues, not as an outside process. Constraining the generalized convolution network to have a circuitry compatible with such a process, may be a qualitative improvement.

{\scriptsize \bibliographystyle{plain} \bibliography{./thalita,./bib/from-keops,./bib/from-sophia}}


\end{document}
