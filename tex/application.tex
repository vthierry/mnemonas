\section{Using this framewrok in different contexts} \label{application}

In this section we review classical mechanism of estimation that can make use of the previous estimation mechanism. 

\subsection*{Considering a supervised learning paradigm.}

If we focus on a supervised learning paradigm, we consider learning sequences of size $T$ with desired output $\bar{\bf o}(t), 0 \le t < T$, corresponding to the input $\bar{\bf i}(t)$, in order to adjust the weights. 

This setup includes without loss of generality the possibility to use several epochs (i.e., several sequences): They are simply concatenated with a period of time with state reset at the end of each epoch, in order to guaranty to have independent state sequences.

With respect to desired output $\bar{o}_n(t)$ we can write:
\[ 
\rho_{nt}(\hat{x}_n(t)) = \frac{\kappa_{nt}}{2} (\hat{x}_n(t) - \bar{o}_n(t))^2
\]

On one hand, we choose $\kappa_{nt} > 0$ if $\bar{o}_n(t)$ is defined (output node) and $\kappa_{nt} = 0$ otherwise (hidden unit, missing data, or segmentation of the sequence in different epochs, see Fig.~\ref{epoch-concatenation}), while since $\kappa_{nt} \in [0, +\infty[$ it can also act as error gain, taking related precision into account. 

\begin{figure}[!ht]
  \includegraphics[width=0.8\textwidth]{img/epoch-concatenation}
  \caption{If the supervised learning is performed with different epoch of data, this is equivalent to a unique epoch, providing a reset segment of length $R$, the maximal recurrent range, is inserted before each new epoch. During reset segment, we set $\kappa_{nt}  = 0$.}
  \label{epoch-concatenation}
\end{figure}

One aspect of the estimation is related to robustness, i.e., being able to take into account the fact that errors and artifacts may occur in the learning set, implemented here as a M-estimator, i.e., not  a least-square function but another alternative cost function, with a smaller slope for higher values.

\subsubsection*{Considering static estimation.}

The present framework stands for dynamic estimation of a temporal sequence. It can also simply be applied to a static estimation at the final time step $T-1$ considering $\bar{o}_n(T-1)$ only the previous values $o_n(t)$ being unconstrained. In that case the value $T$ corresponds to the number of iteration to obtain the desired estimation. In a non-recurrent architecture this value is easy to derive from the architecture, it corresponds to the number of computation steps. In a recurrent architecture, the situation is more complex since computation loops have to converged, and the number of computation steps is an explicit parameter, unless the system is tuned to converge to a fixed point, while considering $T \rightarrow +\infty$ which is a rather straightforward extension of the present work.

\subsection*{Considering constrained architecture and weights values.}

It is precious to also introduce constraints on the connection weights. Typical constraints include: 
\\- sparse connectivity, which reduces the total amount of computation, and allows internal sub-assemblies to emerge, 
\\- positive or negative weight values (corresponding to excitatory or inhibitory connections).

The design choice of the kernels allows us to constraint the network connectivity. It is possible to specify partial connectivity allowing to distinguish different layers (e.g. hidden layers not connected to input and/or output).
This may be, for instance, a 2D-topography with local horizontal connections, or several layers with, e.g., either point to point, or divergent connectivity between layers.

However, if the architecture itself has to be learned, the present framework may be used in another way: Starting from a given connected network and performing a sparse estimation, may lead to a result with zero weight values for connections not present in the estimated architecture, and non zero values otherwise. This is a sparse estimation, i.e. not only minimizing the metric not only with respect to the weights values, but also with respect to the fact that some weights have either zero or non-zero values, i,e, with respect connection sets. Sparse estimation methods (see e.g. \cite{tropp:04a,tropp:04b} for a didactic introduction) can be used to this end. 

One application could be modulatory weighted connections, allowing to enhance or cancel sub-parts of the network connectivity.

In our case we may simply choose, for some meta-parameters $\nu_{nd}$: 
\[
{\cal R}({\bf W}) = \sum_{nd} \frac{\nu_{nd}}{\epsilon + |\hat{W}_{nd}|} \, W_{nd}^2
\]
where $\hat{W}_{nd}$ stands for the best a-priory or previous estimation of the weight. This leads to a reweighted least-square criterion, where small weights value minimization is reinforced, up to $0$, yielding sparse estimation.

The case where we consider excitatory or inhibitory connections (i.e., weight values that only positive or negative), or the case where the weights are bounded, is managed at the implementation level, as a hard constraint in the minimization. Very simply, if the value is beyond the bound it is reprojected on on the bound. This may lead to a sub-optimal estimation, but avoids the heavy management of Karush-Kuhn-Tucker conditions.

As an example, let us consider the adjustable leak $\gamma_{nt}$, $0 \leq \gamma_{nt} \leq 0.99 \simeq 1$ of a NLN unit. If the minimization process yields a negative value, the value is reset to zero (it means that we better have no leak). If the minimization process yields an unstable value higher than one, it is reset to, say, $0.99$ to be sure the system will not diverge.

\subsection*{Considering un-supervised regularization.}

In order to find an interesting solution, we have to constraint the hidden activity to be estimated. Interesting properties includes sparseness, orthogonality, robustness and bounds.

Sparse activity (i.e., with a maximal number of values closed or equal to zero), which is known to correspond to unit assemblies tuned to a given class of input statistics, can be specified as a reweighted least-square criterion again, for some meta-parameters $\kappa_{nd}$:
\[
\rho_{nt}(x_{nt}) = \frac{\kappa_{nd}}{\epsilon + |\hat{x}_{nt}|} \, x_{nt}^2
\]
where $\hat{x}_{nd}$ stands for the previous estimation, with an initial value equal to $\kappa_{nd}$.

Orthogonality of hidden unit activities, in order to avoid redundancy and maximize the dynamic space dimension in the recurrent network, can also be specified, the same way as :
\[
\rho_{nt}(x_{nt}) = \kappa_{nd} \, \sum_{n' \neq n} (\sum_t x_{nt} \, \hat{x}_{n't})^2
\]
again as as, now not local but global, reweighted least-square criterion, now minimizing the dot products between unit activities, thus minimal when orthogonal. 

Another aspect concerns the fact we may have to control the activity bound, e.g., a weak constraint of the form $x_{nt} \preceq b$. Following the same heuristic, we may introduce a cost of the form:
\[
\rho_{nt}(x_{nt}) = \kappa_{nd} \, e^{k\,(x_{nt} - b)}
\]
with $k > 0$ in order to have a fast increasing function as soon as the bound is violated.
